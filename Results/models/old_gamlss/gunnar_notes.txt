# get model
model = sklearn.linear_model.RidgeCV(alphas=np.linspace(1E-5,100,20), fit_intercept=False, store_cv_values=True)

# fit model
model.fit(X,Y)

# get best alpha
In [75]: model.alpha_
Out[75]: 26.31579684210526

# tekhonorov with this alpha should give you same coefficients as regression function from sklearn
np.linalg.solve(X.T.dot(X) + model.alpha_*np.eye(112), X.T.dot(Y))
Out[90]: 
array([ 2.46600571e-02, -6.07943026e-03,  5.46825643e-03,  2.85265747e-03,
       -5.01930302e-03, -3.90274010e-03, -2.22843884e-03,  1.10300369e-02,
       -2.50746381e-03, -9.96524306e-03, -1.01504295e-02,  1.33489136e-03,
        3.25123003e-02,  2.22439379e-02,  5.13401968e-03, -3.39605177e-02,
        1.06240828e-02,  1.24136601e-02, -2.54239245e-02, -1.03925284e-02,
        3.20005098e-03,  3.39343366e-02,  6.39737420e-03,  1.04792146e-02,
       -9.80022523e-03,  1.74081519e-02, -1.93097450e-02,  2.60593047e-02,
       -5.07060709e-02,  2.66217320e-03,  3.48136184e-03, -3.73795797e-03,
       -2.85827499e-03,  1.55820975e-03, -1.20679433e-03, -1.54694634e-03,
       -1.54011173e-03, -1.64419084e-03, -6.50143020e-03, -2.36886422e-03,
       -8.51907769e-04,  1.07210434e-02, -3.47066407e-03, -7.30155402e-04,
       -6.45495484e-03,  4.05410700e-03,  1.92781882e-03, -6.35790289e-03,
       -1.86757784e-03,  1.71547868e-03,  2.91755491e-03, -5.16217305e-03,
        5.69657168e-03,  4.24230969e-03,  2.35860633e-03,  2.60869110e-03,
        5.58057794e-03, -5.58899036e-04, -4.96310733e-03, -8.86476758e-04,
        2.33392033e-03,  5.49814173e-03, -3.37551939e-03,  8.16501099e-03,
        4.43621762e-03,  4.28579549e-04,  4.59176866e-03, -1.95671954e-04,
       -2.15553898e-03,  2.01470183e-03,  5.90206557e-03, -1.21851923e-02,
        3.02510099e-03, -2.24649571e-03, -9.19524831e-03,  1.61329268e-02,
       -8.79963783e-03, -3.08812170e-02,  1.51316701e-03,  2.59310795e-03,
       -3.69528376e-03, -7.34396358e-05, -8.09872144e-03,  4.27565463e-03,
        1.54539162e-02, -8.51317239e-03,  1.24695757e-02,  6.52047787e-03,
       -5.49567374e-03,  3.07526367e-03,  3.59619265e-03, -1.63581022e-03,
       -2.02515073e-04,  2.56175886e-03, -1.49645693e-03, -3.13541074e-03,
       -1.36280692e-03,  6.41753760e-04,  5.86478703e-04,  1.54764548e-03,
       -3.08137084e-04, -3.41980209e-03, -8.56138469e-04,  6.84944092e-03,
        8.39377588e-03,  2.62008428e-03, -7.46673429e-03, -6.82908378e-03,
       -8.01511433e-03,  1.54229062e-03, -1.88240533e-02,  1.75176924e-03])